---
title: "Intrinsic fluctuations of reinforcement learning promote cooperation"
collection: publications
permalink: /publication/2022-10-01-paper-title-number-10
excerpt: 'In this work, we ask for and answer what makes classical temporal-difference reinforcement learning with ùúñ
-greedy strategies cooperative. Cooperating in social dilemma situations is vital for animals, humans, and machines. While evolutionary theory revealed a range of mechanisms promoting cooperation, the conditions under which agents learn to cooperate are contested. Here, we demonstrate which and how individual elements of the multi-agent learning setting lead to cooperation. We use the iterated Prisoner‚Äôs dilemma with one-period memory as a testbed. Each of the two learning agents learns a strategy that conditions the following action choices on both agents‚Äô action choices of the last round. We find that next to a high caring for future rewards, a low exploration rate, and a small learning rate, it is primarily intrinsic stochastic fluctuations of the reinforcement learning process which double the final rate of cooperation to up to 80%. Thus, inherent noise is not a necessary evil of the iterative learning process. It is a critical asset for the learning of cooperation. However, we also point out the trade-off between a high likelihood of cooperative behavior and achieving this in a reasonable amount of time. Our findings are relevant for purposefully designing cooperative algorithms and regulating undesired collusive effects.
'
date: 2023-01-24
venue: 'Scientific Reports'
paperurl: 'https://doi.org/10.1038/s41598-023-27672-7'
citation: 'Barfuss, W., & Meylahn, J. M. (2023). &quot;Intrinsic fluctuations of reinforcement learning promote cooperation&quot; <i>Scientific Reports </i>. 13(1309).'
---

[Download paper here](https://doi.org/10.1038/s41598-023-27672-7)

Recommended citation: Barfuss, W., Meylahn, J.M. (2023) Intrinsic fluctuations of reinforcement learning promote cooperation. Sci Rep 13, 1309.

